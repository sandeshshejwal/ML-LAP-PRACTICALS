{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3b32653b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b895a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/sandeshshejwal/Documents/ML PRACTICALS/spam_ham_dataset 2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f4e4230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12297972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>label_num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2349</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3624</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4685</td>\n",
       "      <td>spam</td>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2030</td>\n",
       "      <td>ham</td>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 label                                               text  \\\n",
       "0         605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1        2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2        3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3        4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4        2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "   label_num  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          1  \n",
       "4          0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "319e1dcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 5171 data email\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis=1)\n",
    "df.head()\n",
    "print('Total %s data email'% len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1c58839c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "ham     3672\n",
       "spam    1499\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#total class memebers\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c8307769",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data preprocessing\n",
    "#data text cleaning\n",
    "# punchuations\n",
    "punct = []\n",
    "for char in string.punctuation:\n",
    "    punct.append(char)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "750e6575",
   "metadata": {},
   "outputs": [],
   "source": [
    " import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "68d770a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(txt):\n",
    "    # case folding\n",
    "    text = txt.lower()\n",
    "    \n",
    "    # remove multiple space, tabs, dan newlines\n",
    "    text = re.sub('\\s+',' ',text)    \n",
    "    # remove links\n",
    "    text = text.replace(\"http://\", \" \").replace(\"https://\", \" \")    \n",
    "    # remove special characters\n",
    "    text = text.encode('ascii', 'replace').decode('ascii')\n",
    "    text = ' '.join(re.sub(\"([@#][A-Za-z0-9]+)|(\\w+:\\/\\/\\S+)\",\" \", text).split())    \n",
    "    # remove punctuation\n",
    "    text = ''.join([word for word in text if word not in punct])    \n",
    "    #remove single character\n",
    "    text = re.sub(r\"\\b[a-zA-Z]\\b\", \"\", text)    \n",
    "    #remove numbers\n",
    "    text = re.sub(r\"\\d+\", \"\", text)    \n",
    "    #remove multiple spaces (again)\n",
    "    text = re.sub('\\s+',' ',text)    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "34f61aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_cleaned</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: enron methanol ; meter # : 988291\\r\\n...</td>\n",
       "      <td>subject enron methanol meter this is follow up...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: hpl nom for january 9 , 2001\\r\\n( see...</td>\n",
       "      <td>subject hpl nom for january see attached file ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: neon retreat\\r\\nho ho ho , we ' re ar...</td>\n",
       "      <td>subject neon retreat ho ho ho we re around to ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: photoshop , windows , office . cheap ...</td>\n",
       "      <td>subject photoshop windows office cheap main tr...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: re : indian springs\\r\\nthis deal is t...</td>\n",
       "      <td>subject re indian springs this deal is to book...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3  Subject: photoshop , windows , office . cheap ...   \n",
       "4  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "\n",
       "                                        text_cleaned label  \n",
       "0  subject enron methanol meter this is follow up...   ham  \n",
       "1  subject hpl nom for january see attached file ...   ham  \n",
       "2  subject neon retreat ho ho ho we re around to ...   ham  \n",
       "3  subject photoshop windows office cheap main tr...  spam  \n",
       "4  subject re indian springs this deal is to book...   ham  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# call function for cleaning\n",
    "    # apply fungsi cleaning ke setiap text\n",
    "df['text_cleaned'] = df['text'].apply(lambda x: cleaning(x))\n",
    "df = df[['text', 'text_cleaned', 'label']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4c018b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subject: enron methanol ; meter # : 988291\r\n",
      "this is a follow up to the note i gave you on monday , 4 / 3 / 00 { preliminary\r\n",
      "flow data provided by daren } .\r\n",
      "please override pop ' s daily volume { presently zero } to reflect daily\r\n",
      "activity you can obtain from gas control .\r\n",
      "this change is needed asap for economics purposes .\n",
      "subject enron methanol meter this is follow up to the note gave you on monday preliminary flow data provided by daren please override pop daily volume presently zero to reflect daily activity you can obtain from gas control this change is needed asap for economics purposes \n"
     ]
    }
   ],
   "source": [
    "#compare\n",
    "print(df['text'][0])\n",
    "print(df['text_cleaned'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "81d7bbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sandeshshejwal/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/sandeshshejwal/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/sandeshshejwal/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/sandeshshejwal/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# to remove stop words\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "stop = stopwords.words('english')\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: ' '.join([word for word in x.split() if word not in stop]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71061333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def get_wordnet_pos(word):\n",
    "    \"\"\"Map POS tag to the first character lemmatize() accepts\"\"\"\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "    return tag_dict.get(tag, wordnet.NOUN)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d4b7f4cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'label'], dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def do_lemma(string):\n",
    "    lemmatized = ' '.join([lemmatizer.lemmatize(word, get_wordnet_pos(word)) for word in nltk.word_tokenize(string)])\n",
    "    return lemmatized\n",
    "\n",
    "df['text_cleaned'] = df['text_cleaned'].apply(lambda x: do_lemma(x))\n",
    "\n",
    "df = df.drop(['text'], axis=1)\n",
    "df = df.rename(columns = {'text_cleaned' : 'text'})\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "18ab4b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(df['text'])\n",
    "y = df['label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "75738e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e89b8863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "# defining the classifier\n",
    "clf = KNeighborsClassifier(n_neighbors=5, metric='euclidean')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a7df2087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training time: 0.01 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predicting the time of train and testing\n",
    "t0 = time()\n",
    "clf.fit(X_train, y_train)\n",
    "print(\"\\nTraining time:\", round(time()-t0, 3), \"s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ca279d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting time: 1.872 s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#predicting the time of  testing\n",
    "t1 = time()\n",
    "pred = clf.predict(X_test)\n",
    "print(\"Predicting time:\", round(time()-t1, 3), \"s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "5a16b845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of KNN Algorithm:  0.9623188405797102\n"
     ]
    }
   ],
   "source": [
    "#calculating and printing the accuracy of the algorithm\n",
    "print(\"Accuracy of KNN Algorithm: \", accuracy_score(pred,y_test))\n",
    "# tested ok 16/09/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3114dd0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
